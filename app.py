import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import segmentation_models_pytorch as smp
import torch
from tqdm import tqdm
import numpy as np
import rasterio


DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = './model.pth'
PATCH_SIZE = 512  # –†–∞–∑–º–µ—Ä –ø–∞—Ç—á–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å
STRIDE = 512
THRESHOLD = 0.5


def predict_sliding_window(model, full_image, patch_size=512, stride=512, device='cpu'):
    """
    –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞.
    
    :param model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Pytorch.
    :param full_image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ numpy array (H, W, C).
    :param patch_size: –†–∞–∑–º–µ—Ä –ø–∞—Ç—á–∞.
    :param stride: –®–∞–≥, —Å –∫–æ—Ç–æ—Ä—ã–º –¥–≤–∏–≥–∞–µ—Ç—Å—è –æ–∫–Ω–æ. –ú–µ–Ω—å—à–µ patch_size –¥–ª—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è.
    :param device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π ('cuda' –∏–ª–∏ 'cpu').
    :return: –§–∏–Ω–∞–ª—å–Ω–∞—è –º–∞—Å–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (H, W).
    """
    model.eval()
    H, W, _ = full_image.shape
    
    full_image_float = full_image.astype(np.float32)
    
    prediction_map = np.zeros((H, W), dtype=np.float32)
    counts_map = np.zeros((H, W), dtype=np.float32)

    for y in tqdm(range(0, H, stride), desc="Sliding Window Inference"):
        for x in range(0, W, stride):
            y_end = min(y + patch_size, H)
            x_end = min(x + patch_size, W)
            
            patch = full_image_float[y:y_end, x:x_end]
            
            h_patch, w_patch, _ = patch.shape
            padded_patch = np.zeros((patch_size, patch_size, 3), dtype=np.float32)
            padded_patch[:h_patch, :w_patch] = patch
            
            input_tensor = torch.from_numpy(padded_patch.transpose(2, 0, 1)).float().unsqueeze(0).to(device)
            
            with torch.no_grad():
                output = model(input_tensor)
                pred_prob = torch.sigmoid(output).squeeze().cpu().numpy()
            
            prediction_map[y:y_end, x:x_end] += pred_prob[:h_patch, :w_patch]
            counts_map[y:y_end, x:x_end] += 1
            

    counts_map[counts_map == 0] = 1
    final_prediction = prediction_map / counts_map
    
    return final_prediction


def haversine_distance(lat1, lon1, lat2, lon2):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–≤ –º–µ—Ç—Ä–∞—Ö) –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏ –Ω–∞ –ó–µ–º–ª–µ
    –ø–æ –∏—Ö —à–∏—Ä–æ—Ç–∞–º –∏ –¥–æ–ª–≥–æ—Ç–∞–º.
    
    :param lat1, lon1: –®–∏—Ä–æ—Ç–∞ –∏ –¥–æ–ª–≥–æ—Ç–∞ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏ (–≤ –≥—Ä–∞–¥—É—Å–∞—Ö).
    :param lat2, lon2: –®–∏—Ä–æ—Ç–∞ –∏ –¥–æ–ª–≥–æ—Ç–∞ –≤—Ç–æ—Ä–æ–π —Ç–æ—á–∫–∏ (–≤ –≥—Ä–∞–¥—É—Å–∞—Ö).
    :return: –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –º–µ—Ç—Ä–∞—Ö.
    """
    R = 6371000  # –†–∞–¥–∏—É—Å –ó–µ–º–ª–∏ –≤ –º–µ—Ç—Ä–∞—Ö
    
    phi1 = np.deg2rad(lat1)
    phi2 = np.deg2rad(lat2)
    delta_phi = np.deg2rad(lat2 - lat1)
    delta_lambda = np.deg2rad(lon2 - lon1)
    
    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
    
    distance = R * c
    
    return distance


def get_pixel_size_m2(tiff_path: str):
    with rasterio.open(tiff_path) as src:
        if not src.crs.is_geographic:
            transform = src.transform
            x_scale = transform.a
            y_scale = -transform.e
            if x_scale > 0 and y_scale > 0:
                pixel_area = x_scale * y_scale
                return pixel_area
    
        lon1, lat1, lon2, lat2 = src.bounds
        width = haversine_distance(lat1, lon1, lat1, lon2)
        height = haversine_distance(lat1, lon1, lat2, lon1)
        xscale = width/src.width
        yscale = height/src.height
        return xscale*yscale
    

def calculate_building_area(pred_mask_binary, scale):
    return np.sum(pred_mask_binary)*scale


model = smp.Unet(encoder_name="resnet50", encoder_weights="imagenet", in_channels=3, classes=1)

st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ –ø–ª–æ—â–∞–¥–∏ –∑–∞—Å—Ç—Ä–æ–π–∫–∏",
    page_icon="üèòÔ∏è",
    layout="wide"
)

st.title('üèòÔ∏è –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –ø–ª–æ—â–∞–¥–∏ –∑–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —Å–ø—É—Ç–Ω–∏–∫–æ–≤–æ–º—É —Å–Ω–∏–º–∫—É')
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≥–µ–æ–ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–π TIFF-—Ñ–∞–π–ª, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é –º–∞—Å–∫—É –∑–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –æ–±—â—É—é –ø–ª–æ—â–∞–¥—å –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∞—Ö.")


@st.cache_resource
def load_model(model_path, device):

    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    return model

DEVICE = torch.device("cpu")
try:
    with st.spinner('–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.'):
        model = load_model('model.pth', DEVICE)
    st.success('–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!')
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
    st.stop()


uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ GeoTIFF —Ñ–∞–π–ª (*.tif, *.tiff)", 
    type=['tif', 'tiff']
)


if uploaded_file is not None:
    with open("temp_image.tif", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.info("–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω. –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
    
    try:
        # --- –®–∞–≥ 1: –†–∞—Å—á–µ—Ç GSD –∏ –ø–ª–æ—â–∞–¥–∏ –ø–∏–∫—Å–µ–ª—è ---
        with st.spinner('–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–ø—Ä–∏–≤—è–∑–∫–∏...'):
            pixel_area = get_pixel_size_m2("temp_image.tif")
        
        if pixel_area is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞—Å—à—Ç–∞–± –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è –≥–µ–æ–ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º GeoTIFF.")
            st.stop()
        
        st.success(f"–ú–∞—Å—à—Ç–∞–± –æ–ø—Ä–µ–¥–µ–ª–µ–Ω. –ü–ª–æ—â–∞–¥—å –æ–¥–Ω–æ–≥–æ –ø–∏–∫—Å–µ–ª—è: {pixel_area:.4f} –º¬≤.")
        
        # --- –®–∞–≥ 2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏ ---
        image = cv2.imread("temp_image.tif")
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        with st.spinner('–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è... –≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–∏–º.'):
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è sliding window
            PATCH_SIZE = 512
            STRIDE = 256
            THRESHOLD = 0.5
            
            pred_probs = predict_sliding_window(model, image_rgb, PATCH_SIZE, STRIDE, DEVICE)
            binary_mask = (pred_probs > THRESHOLD).astype(np.uint8)

        st.success("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

        # --- –®–∞–≥ 3: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
        building_pixel_count = np.sum(binary_mask)
        total_area = building_pixel_count * pixel_area

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        st.metric(label="–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –∑–∞—Å—Ç—Ä–æ–π–∫–∏", value=f"{total_area:,.2f} –º¬≤")
        
        # --- –®–∞–≥ 4: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ---
        st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(image_rgb, caption='–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)
        
        with col2:
            st.image(binary_mask * 255, caption='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Å–∫–∞ –∑–∞—Å—Ç—Ä–æ–π–∫–∏', use_container_width=True)
            
    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞.")